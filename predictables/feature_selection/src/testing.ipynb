{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from predictables.feature_selection.src._backward_stepwise import (\n",
    "    backward_stepwise_feature_selection,\n",
    "    initialize_feature_set,\n",
    "    calculate_all_feature_correlations,\n",
    "    identify_highly_correlated_pairs,\n",
    "    generate_X_y,\n",
    "    evaluate_feature_removal_impact,\n",
    "    select_feature_to_remove,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import (\n",
    "    PolynomialFeatures,\n",
    "    PowerTransformer,\n",
    "    FunctionTransformer,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Generate a dataset with explicitly correlated features\n",
    "fold_numbers = np.tile(np.arange(1, 11), 100)\n",
    "\n",
    "# Add 100 fold 0 samples to ensure all folds have data\n",
    "fold_numbers = np.concatenate([fold_numbers, np.zeros(500)])\n",
    "rng.shuffle(fold_numbers)\n",
    "base_feature = rng.normal(0, 1, size=1500)\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    {\n",
    "        \"fold\": fold_numbers,\n",
    "        \"feature1\": base_feature,  # Base feature\n",
    "        \"feature2\": base_feature * 1.01\n",
    "        + rng.normal(0, 0.01, size=1500),  # Almost the same as feature1\n",
    "        \"feature3\": base_feature * 0.99\n",
    "        + rng.normal(0, 0.01, size=1500),  # Almost the same as feature1\n",
    "        \"feature4\": rng.lognormal(0, 1, size=1500),  # Independent high-impact feature\n",
    "        \"feature5\": rng.beta(2, 5, size=1500),  # Another independent feature\n",
    "    }\n",
    ")\n",
    "\n",
    "# Target variable not strongly influenced by correlated features to ensure they are deemed less important\n",
    "X[\"y\"] = (\n",
    "    (2 * X[\"feature4\"] + X[\"feature5\"] + rng.normal(0, 1, size=1500)) > 1.5\n",
    ").astype(int)\n",
    "y = X[\"y\"]\n",
    "X = X.drop(columns=\"y\")\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "original_features = set(X.columns)\n",
    "\n",
    "# Assertions to verify that not all correlated features are retained\n",
    "correlated_features = {\"feature1\", \"feature2\", \"feature3\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('feature1', 'feature2'), ('feature1', 'feature3'), ('feature2', 'feature3')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize_feature_set,\n",
    "# calculate_all_feature_correlations,\n",
    "# identify_highly_correlated_pairs,\n",
    "# generate_X_y,\n",
    "# evaluate_feature_removal_impact,\n",
    "# select_feature_to_remove\n",
    "corr = calculate_all_feature_correlations(X)\n",
    "identify_highly_correlated_pairs(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "FEATURE 1:\n",
      "mean without: 85.5%\n",
      "mean with: 84.7%\n",
      "sd with: 3.1%\n",
      "lower bound: 81.6%\n",
      "\n",
      "\n",
      "FEATURE 2:\n",
      "mean without: 85.7%\n",
      "mean with: 84.7%\n",
      "sd with: 3.1%\n",
      "lower bound: 81.6%\n",
      "\n",
      "\n",
      "FEATURE 3:\n",
      "mean without: 85.2%\n",
      "mean with: 84.7%\n",
      "sd with: 3.1%\n",
      "lower bound: 81.6%\n"
     ]
    }
   ],
   "source": [
    "res = {\"feature1\": {}, \"feature2\": {}, \"feature3\": {}}\n",
    "for i in range(1, 4):\n",
    "    w, wo = evaluate_feature_removal_impact(X, y, model, f\"feature{i}\", 5, 9)\n",
    "    print(\n",
    "        f\"\\n\\nFEATURE {i}:\\nmean without: {np.mean(wo):.1%}\\nmean with: {np.mean(w):.1%}\\nsd with: {np.std(w):.1%}\\nlower bound: {np.mean(w) - np.std(w):.1%}\"\n",
    "    )\n",
    "\n",
    "    res[f\"feature{i}\"][\"with\"] = w\n",
    "    res[f\"feature{i}\"][\"without\"] = wo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'feature2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, j = 2, 3\n",
    "\n",
    "select_feature_to_remove(\n",
    "    res[f\"feature{i}\"][\"with\"],\n",
    "    res[f\"feature{i}\"][\"without\"],\n",
    "    f\"feature{i}\",\n",
    "    res[f\"feature{j}\"][\"with\"],\n",
    "    res[f\"feature{j}\"][\"without\"],\n",
    "    f\"feature{j}\",\n",
    "    1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature selection\n",
    "selected_features = backward_stepwise_feature_selection(\n",
    "    X, y, model, start_fold=5, end_fold=9, tolerance=0.1\n",
    ")\n",
    "\n",
    "removed_features = original_features - set(selected_features)\n",
    "retained_features = set(selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
